{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b20464f7ecbf458c87ebf52b6e7e1ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df9170d392994aef81a23d5883cfb0fb",
              "IPY_MODEL_3e333ed0ee6144f78b25f132bce02f15"
            ],
            "layout": "IPY_MODEL_2a2233de95454657af4787bef4e824b9"
          },
          "model_module_version": "1.5.0"
        },
        "df9170d392994aef81a23d5883cfb0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed1535008ec41d689c72e6b623857ad",
            "max": 305203025,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e81e2e147ce424fbe20872e392bb752",
            "value": 305203025
          },
          "model_module_version": "1.5.0"
        },
        "3e333ed0ee6144f78b25f132bce02f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02e62e0aa2e84d3fbad62d31f793f008",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8589d6bc84304d38ae1d2cdf3efc93e7",
            "value": " 305M/305M [00:22&lt;00:00, 13.3MB/s]"
          },
          "model_module_version": "1.5.0"
        },
        "2a2233de95454657af4787bef4e824b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "9ed1535008ec41d689c72e6b623857ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "5e81e2e147ce424fbe20872e392bb752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          },
          "model_module_version": "1.5.0"
        },
        "02e62e0aa2e84d3fbad62d31f793f008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "8589d6bc84304d38ae1d2cdf3efc93e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          },
          "model_module_version": "1.5.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61vAqtSq2m5k",
        "outputId": "70d0bd6a-d918-4368-d3a2-2ac129a04340"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDi4UirffQax",
        "outputId": "7a1f9f52-1eab-4f16-b799-6cb0533aa966"
      },
      "source": [
        "!pip install -q snorkel spacy-nightly[transformers,cuda100] --pre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369.7MB 45kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122kB 50.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 32.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1MB 29.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.8MB 31.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 38.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 25.6MB/s \n",
            "\u001b[?25h  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorboard~=2.5, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6QygOmmc0fZ",
        "outputId": "bb6b96f4-7786-495e-a26c-d5050206fdb3"
      },
      "source": [
        "import string\n",
        "import spacy\n",
        "import spacy_transformers\n",
        "import pandas as pd\n",
        "\n",
        "from spacy.cli import download\n",
        "download(\"en_core_web_trf\")\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_trf\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_trf')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/util.py:693: UserWarning: [W095] Model 'en_core_web_trf' (3.0.0) requires spaCy >=3.0.0,<3.1.0 and is incompatible with the current version (3.0.0rc5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4aeqk_faEtB"
      },
      "source": [
        "!pip install -q sent2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7FLz8FIaAjL"
      },
      "source": [
        "from scipy import spatial\n",
        "from sent2vec.vectorizer import Vectorizer\n",
        "vectorizer = Vectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JTh_WbAEzMU"
      },
      "source": [
        "# Part I Check the answer is relevant to the question or not "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A-CCosYFHYl"
      },
      "source": [
        "Some approaches I have been researching:\n",
        "> **1 Intent Recognition.** We need to label the intent of the answer based on the intent of the question which we already have. To detect irrelevant answers we need a `irrelevant` label. i.e:\n",
        ">> Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities? -> `self_improvement` <br>\n",
        "A: Yes, I do. I have improved my technical skill as well as my ability of team working. -> `self_improvement` <br>\n",
        "A: Yes, I do. I play basketball very well ->  `irrelevant`\n",
        "\n",
        "> This is classification problem, a suppervised learning, but we don't have any data so we can't try now, but it's worth trying when we collect enough data!\n",
        "\n",
        "> **2.Intent Recognition combine Entity Recognition** Entity Recognition makes the intent more specific. i.e:\n",
        ">> Q: In the last year, do you feel you have grown in terms of your `knowledge` and `capabilities`  <br> -> `{intent`:`self_improvement, entites: {knowledge, capabilities}}`\n",
        "\n",
        "> As mentioned above, this is classification problem for both Intent Recognition and Entity Recognition, a suppervised learning, but we don't have any data so I can't try now, but it's worth trying when we collect enough data!\n",
        "\n",
        ">**3. Sentence Similarity**: In this method, I'll calculate the distance (`cosine distance`) between the question and the answer. The intuitive of this is: the closer distance the more similar between question and answer (more relevant). To calculate `cosine distance` I need embed the sentence into vector. To do this, I have three options:\n",
        " - I clean the sentence, just keep main words then use pre-trained model Word2Vec to embedding each word in the sentence then calculate the similarity of all posible pairs of words (one in the answer one in the question) then get the average\n",
        " - I use pre-trained model sent2vec library based on Word2Vec and BERT this is a unsupervised powerful model to embedding semantic of words. <br>\n",
        " - Another option is using pre-trained BERT to embedding the sentence. <br>\n",
        "\n",
        ">After calculating distance, now the question is: which threshold to define relevant or irrelevant? The threshold can be dynamic for sequential data, If we continuously have the label of data then we can update the threshold by statistic formula. This threshold will be the lower bound of outlier. Another approach is that solve the problem by binary classification (when we have data)\n",
        "\n",
        ">**4. Classification - Fine-tuning pre-trained BERT**: In this method I will use the question-answering architecture of BERT to represent the question-answer pairs. Then I add a binary classification layer to learn relevant or irrelevant. \n",
        "\n",
        "**In this test, I use the third approach due to lack of data. But I can take advantage of powerful pre-trained model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4vyv9WrExb9"
      },
      "source": [
        "## Calculate similarity word-pairs using pre-trained Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siQ51Am9dsmD"
      },
      "source": [
        "Using **Spacy** library for text processing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7KUU7dFH9zw"
      },
      "source": [
        "# Define a function to normalize text:\n",
        "def text_processing(text):\n",
        "  # lowercase text\n",
        "  text = text.lower()\n",
        "  doc = nlp(text)\n",
        "  # remove punctuation\n",
        "  doc = [token for token in doc if token.text not in string.punctuation]\n",
        "  # remove stop words \n",
        "  doc = [token for token in doc if not token.is_stop]\n",
        "  # get lemma \n",
        "  doc = [token.lemma_ for token in doc]\n",
        "\n",
        "  return doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zWs2LDJiYW3"
      },
      "source": [
        "Using **pre-trained Word2Vec** for word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Doo2YXxAiXFH",
        "outputId": "be8419db-2030-45d8-9f39-70aec1df101d"
      },
      "source": [
        "import gensim\n",
        "import gensim.downloader\n",
        "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjmGr_oSixH0",
        "outputId": "919c10b3-82b5-48d9-f82d-1a725f371c05"
      },
      "source": [
        "sentences = [\n",
        "    \"In the last year, do you feel you have grown in terms of your knowledge and capabilities?\",\n",
        "    \"Yes, I do. I have improved my technical skill.\",\n",
        "    \"I play basketball very well.\",\n",
        "    \"Yes, I do. I have improved my technical skill as well as my ability of working in a team\",\n",
        "    \"I learned a lot in my school, I worked very hard\",\n",
        "    \"You are so bad.\",\n",
        "    \"I almost learned nothing in the last year, the job is unsuitable with my career path\",\n",
        "    \"I have learned new techniques and improved my communication skill\",\n",
        "    \"Everything seems boring, I did not learn anything\",\n",
        "]\n",
        "\n",
        "cleaned_sentences = []\n",
        "for i, sent in enumerate(sentences):\n",
        "  cleaned_sentences.append(text_processing(sent))\n",
        "\n",
        "def calculate_similarity(doc_1, doc_2):\n",
        "  sim = 0\n",
        "  for token_1 in doc_1:\n",
        "    for token_2 in doc_2:\n",
        "      sim += spatial.distance.cosine(glove_vectors[token_1], glove_vectors[token_2])         #glove_vectors.similarity(token_1, token_2)\n",
        "  if len(doc_2) > 0:\n",
        "    sim /= (len(doc_1)*len(doc_2))\n",
        "    return sim\n",
        "  return 0\n",
        "\n",
        "for i,sent in enumerate(sentences[1:]):\n",
        "  print('Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities?')\n",
        "  print('A:',sentences[i+1])\n",
        "  print('Distance score:', calculate_similarity(cleaned_sentences[0], cleaned_sentences[i+1]))\n",
        "  print('---------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities?\n",
            "A: Yes, I do. I have improved my technical skill.\n",
            "Distance score: 0.7346890200860798\n",
            "---------------\n",
            "Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities?\n",
            "A: I play basketball very well.\n",
            "Distance score: 0.801333483386164\n",
            "---------------\n",
            "Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities?\n",
            "A: Yes, I do. I have improved my technical skill as well as my ability of working in a team\n",
            "Distance score: 0.7133609318130073\n",
            "---------------\n",
            "Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities?\n",
            "A: I learned a lot in my school, I worked very hard\n",
            "Distance score: 0.6978753939270973\n",
            "---------------\n",
            "Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities?\n",
            "A: You are so bad.\n",
            "Distance score: 0.7320054955780506\n",
            "---------------\n",
            "Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities?\n",
            "A: I almost learned nothing in the last year, the job is unsuitable with my career path\n",
            "Distance score: 0.7485620306494335\n",
            "---------------\n",
            "Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities?\n",
            "A: I have learned new techniques and improved my communication skill\n",
            "Distance score: 0.7225984773702092\n",
            "---------------\n",
            "Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities?\n",
            "A: Everything seems boring, I did not learn anything\n",
            "Distance score: 0.7183747862776121\n",
            "---------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfqqb5t3btzb"
      },
      "source": [
        "> We can see that, this approach is not good. The answer \"I learned a lot in my school, I worked very hard\" quiet not related to the question but have the best score (lowest). The two expected answer don't have good score (quiet high)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVWCz9Z0dDJv"
      },
      "source": [
        "## Using Sent2Vec based on pre-trained Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak_rKouqy5Ta"
      },
      "source": [
        "I use 0.65 as threshold for both questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFIa8xKkwJAj"
      },
      "source": [
        "**Question 1** In the last year, do you feel you have grown in terms of your knowledge and capabilities?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nw8zxvOxtIwq",
        "outputId": "385b0c57-4e67-408a-e8a5-30354ec60977"
      },
      "source": [
        "\n",
        "sentences = [\n",
        "    \"In the last year, do you feel you have grown in terms of your knowledge and capabilities?\",\n",
        "    \"Yes, I do. I have improved my technical skill.\",\n",
        "    \"I play basketball very well.\",\n",
        "    \"Yes, I do. I have improved my technical skill as well as my ability of working in a team\",\n",
        "    \"I learned a lot in my school, I worked very hard\",\n",
        "    \"You are so bad.\",\n",
        "    \"I almost learned nothing in the last year, the job is unsuitable with my career path\",\n",
        "    \"I have learned new techniques and improved my communication skill\",\n",
        "    \"Everything seems boring, I did not learn anything\",\n",
        "]\n",
        "tokens_sent = []\n",
        "relevant_sents = []\n",
        "irrelevant_sents = []\n",
        "\n",
        "nlp.vocab[\"not\"].is_stop = False\n",
        "for sent in sentences:\n",
        "  tokens_sent.append(text_processing(sent))\n",
        "\n",
        "vectorizer.word2vec(tokens_sent, pretrained_vectors_path= '/content/drive/MyDrive/lexvec.commoncrawl.300d.W.pos.neg3.vectors')\n",
        "vectors = vectorizer.vectors\n",
        "\n",
        "for i,sent in enumerate(sentences[1:]):\n",
        "  print(sentences[i+1])\n",
        "  if spatial.distance.cosine(vectors[0], vectors[i+1]) < 0.65:\n",
        "    relevant_sents.append(sentences[i+1])\n",
        "  else:\n",
        "    irrelevant_sents.append(sentences[i+1])\n",
        "  print('Distance score:', spatial.distance.cosine(vectors[0], vectors[i+1]))# calculate_similarity(cleaned_sentences[0], cleaned_sentences[i+1]))\n",
        "  print('---------------')\n",
        "\n",
        "print('\\nSummary\\n')\n",
        "print('Relevant answers:\\n')\n",
        "for sent in relevant_sents:\n",
        "  print('\\t-',sent)\n",
        "\n",
        "print('\\nIrrelevant answers:\\n')\n",
        "for sent in irrelevant_sents:\n",
        "  print('\\t-',sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yes, I do. I have improved my technical skill.\n",
            "Distance score: 0.4172677993774414\n",
            "---------------\n",
            "I play basketball very well.\n",
            "Distance score: 0.8272860050201416\n",
            "---------------\n",
            "Yes, I do. I have improved my technical skill as well as my ability of working in a team\n",
            "Distance score: 0.35876572132110596\n",
            "---------------\n",
            "I learned a lot in my school, I worked very hard\n",
            "Distance score: 0.4818311333656311\n",
            "---------------\n",
            "You are so bad.\n",
            "Distance score: 0.7784879803657532\n",
            "---------------\n",
            "I almost learned nothing in the last year, the job is unsuitable with my career path\n",
            "Distance score: 0.4150501489639282\n",
            "---------------\n",
            "I have learned new techniques and improved my communication skill\n",
            "Distance score: 0.42051494121551514\n",
            "---------------\n",
            "Everything seems boring, I did not learn anything\n",
            "Distance score: 0.5333107113838196\n",
            "---------------\n",
            "\n",
            "Summary\n",
            "\n",
            "Relevant answers:\n",
            "\n",
            "\t- Yes, I do. I have improved my technical skill.\n",
            "\t- Yes, I do. I have improved my technical skill as well as my ability of working in a team\n",
            "\t- I learned a lot in my school, I worked very hard\n",
            "\t- I almost learned nothing in the last year, the job is unsuitable with my career path\n",
            "\t- I have learned new techniques and improved my communication skill\n",
            "\t- Everything seems boring, I did not learn anything\n",
            "\n",
            "Irrelevant answers:\n",
            "\n",
            "\t- I play basketball very well.\n",
            "\t- You are so bad.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6wGlPgPyUgK"
      },
      "source": [
        "> One sentence: \"I learned a lot in my school, I worked very hard\" is wrongly classified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcTdIUqgwM4s"
      },
      "source": [
        "**Question. 2** Do you feel the organization's policies and benefits are employee-friendly?,\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yAiti9gKyl5i",
        "outputId": "e8f01805-6fb4-40f7-e7ad-fa49d27a7047"
      },
      "source": [
        "sentences = [\"Do you feel the organization's policies and benefits are employee-friendly?\",\n",
        "             \"I feel the policy of the company is quite good, brings good conditions for employees!\",\n",
        "            \"The company does not have a policy to support employees away from home. Should facilitate working from home or remotely\",\n",
        "            \"Overtime payment is quite low, I'm not satisfied about this\",\n",
        "            \"Hi, how are you\",\n",
        "            \"Just fine, but the company should have more outside activities\",\n",
        "            \"They are so nice to me!\",\n",
        "            \"I have to work early tomorrow\",\n",
        "            \"Everything seems boring, I did not learn anything\",\n",
        "            \"I don't know\",\n",
        "            \"The policies and benefits are good!\"\n",
        "]\n",
        "tokens_sent = []\n",
        "relevant_sents = []\n",
        "irrelevant_sents = []\n",
        "\n",
        "nlp.vocab[\"not\"].is_stop = False\n",
        "for sent in sentences:\n",
        "  tokens_sent.append(text_processing(sent))\n",
        "\n",
        "vectorizer.word2vec(tokens_sent, pretrained_vectors_path= '/content/drive/MyDrive/lexvec.commoncrawl.300d.W.pos.neg3.vectors')\n",
        "vectors = vectorizer.vectors\n",
        "for i,sent in enumerate(sentences[1:]):\n",
        "  #print('Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities?')\n",
        "  print(sentences[i+1])\n",
        "  if spatial.distance.cosine(vectors[0], vectors[i+1]) < 0.65:\n",
        "    relevant_sents.append(sentences[i+1])\n",
        "  else:\n",
        "    irrelevant_sents.append(sentences[i+1])\n",
        "  print('Distance score:', spatial.distance.cosine(vectors[0], vectors[i+1]))# calculate_similarity(cleaned_sentences[0], cleaned_sentences[i+1]))\n",
        "  print('---------------')\n",
        "\n",
        "print('\\nSummary\\n')\n",
        "print('Relevant answers:\\n')\n",
        "for sent in relevant_sents:\n",
        "  print('\\t-',sent)\n",
        "\n",
        "print('\\nIrrelevant answers:\\n')\n",
        "for sent in irrelevant_sents:\n",
        "  print('\\t-',sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I feel the policy of the company is quite good, brings good conditions for employees!\n",
            "Distance score: 0.23459845781326294\n",
            "---------------\n",
            "The company does not have a policy to support employees away from home. Should facilitate working from home or remotely\n",
            "Distance score: 0.273262083530426\n",
            "---------------\n",
            "Overtime payment is quite low, I'm not satisfied about this\n",
            "Distance score: 0.55739426612854\n",
            "---------------\n",
            "Hi, how are you\n",
            "Distance score: 0.9538920782506466\n",
            "---------------\n",
            "Just fine, but the company should have more outside activities\n",
            "Distance score: 0.5377933084964752\n",
            "---------------\n",
            "They are so nice to me!\n",
            "Distance score: 0.7342964112758636\n",
            "---------------\n",
            "I have to work early tomorrow\n",
            "Distance score: 0.7378312945365906\n",
            "---------------\n",
            "Everything seems boring, I did not learn anything\n",
            "Distance score: 0.6842125952243805\n",
            "---------------\n",
            "I don't know\n",
            "Distance score: 0.7175776660442352\n",
            "---------------\n",
            "The policies and benefits are good!\n",
            "Distance score: 0.22672039270401\n",
            "---------------\n",
            "\n",
            "Summary\n",
            "\n",
            "Relevant answers:\n",
            "\n",
            "\t- I feel the policy of the company is quite good, brings good conditions for employees!\n",
            "\t- The company does not have a policy to support employees away from home. Should facilitate working from home or remotely\n",
            "\t- Overtime payment is quite low, I'm not satisfied about this\n",
            "\t- Just fine, but the company should have more outside activities\n",
            "\t- The policies and benefits are good!\n",
            "\n",
            "Irrelevant answers:\n",
            "\n",
            "\t- Hi, how are you\n",
            "\t- They are so nice to me!\n",
            "\t- I have to work early tomorrow\n",
            "\t- Everything seems boring, I did not learn anything\n",
            "\t- I don't know\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDRFr43z81TL"
      },
      "source": [
        "> All sentences are classified correctly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-719DNNB-HiI"
      },
      "source": [
        "## Using Sent2Vec based on pre-trained BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnyJsP33zIK-"
      },
      "source": [
        "I use 0.1 as threshold for both question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC8F4yw9CcQT"
      },
      "source": [
        "**Question 1** In the last year, do you feel you have grown in terms of your knowledge and capabilities?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeGlWcIBCPn_",
        "outputId": "deff5cbc-2f32-48bd-9e79-4fae36bb3fe9"
      },
      "source": [
        "sentences = [\n",
        "    \"In the last year, do you feel you have grown in terms of your knowledge and capabilities?\",\n",
        "    \"Yes, I do. I have improved my technical skill.\",\n",
        "    \"I play basketball very well.\",\n",
        "    \"Yes, I do. I have improved my technical skill as well as my ability of working in a team\",\n",
        "    \"I learned a lot in my school, I worked very hard\",\n",
        "    \"You are so bad.\",\n",
        "    \"I almost learned nothing in the last year, the job is unsuitable with my career path\",\n",
        "    \"I have learned new techniques and improved my communication skill\",\n",
        "    \"Everything seems boring, I did not learn anything\",\n",
        "]\n",
        "\n",
        "relevant_sents = []\n",
        "irrelevant_sents = []\n",
        "for i,sent in enumerate(sentences[1:]):\n",
        "  vectorizer.bert([sentences[0],sent])\n",
        "  vectors_bert = vectorizer.vectors\n",
        "#  print('Q:',sentences[0])\n",
        "  print(sentences[i+1])\n",
        "  if  spatial.distance.cosine(vectors_bert[0], vectors_bert[1]) < 0.1:\n",
        "#    print('Relevant')\n",
        "    relevant_sents.append(sent)\n",
        "  else:\n",
        "    irrelevant_sents.append(sent)\n",
        " #   print('Irrelevant')\n",
        "  print('Distance score:', spatial.distance.cosine(vectors_bert[0], vectors_bert[1]))# calculate_similarity(cleaned_sentences[0], cleaned_sentences[i+1]))\n",
        "  print('---------------')\n",
        "print('\\nSummary\\n')\n",
        "print('Relevant answers:\\n')\n",
        "for sent in relevant_sents:\n",
        "  print('\\t-',sent)\n",
        "\n",
        "print('\\nIrrelevant answers:\\n')\n",
        "for sent in irrelevant_sents:\n",
        "  print('\\t-',sent)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yes, I do. I have improved my technical skill.\n",
            "Distance score: 0.06629043817520142\n",
            "---------------\n",
            "I play basketball very well.\n",
            "Distance score: 0.1992979645729065\n",
            "---------------\n",
            "Yes, I do. I have improved my technical skill as well as my ability of working in a team\n",
            "Distance score: 0.0367618203163147\n",
            "---------------\n",
            "I learned a lot in my school, I worked very hard\n",
            "Distance score: 0.15720242261886597\n",
            "---------------\n",
            "You are so bad.\n",
            "Distance score: 0.226995050907135\n",
            "---------------\n",
            "I almost learned nothing in the last year, the job is unsuitable with my career path\n",
            "Distance score: 0.059124886989593506\n",
            "---------------\n",
            "I have learned new techniques and improved my communication skill\n",
            "Distance score: 0.08694076538085938\n",
            "---------------\n",
            "Everything seems boring, I did not learn anything\n",
            "Distance score: 0.15345317125320435\n",
            "---------------\n",
            "\n",
            "Summary\n",
            "\n",
            "Relevant answers:\n",
            "\n",
            "\t- Yes, I do. I have improved my technical skill.\n",
            "\t- Yes, I do. I have improved my technical skill as well as my ability of working in a team\n",
            "\t- I almost learned nothing in the last year, the job is unsuitable with my career path\n",
            "\t- I have learned new techniques and improved my communication skill\n",
            "\n",
            "Irrelevant answers:\n",
            "\n",
            "\t- I play basketball very well.\n",
            "\t- I learned a lot in my school, I worked very hard\n",
            "\t- You are so bad.\n",
            "\t- Everything seems boring, I did not learn anything\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW-mPTlTq_Fj"
      },
      "source": [
        "> One sentence \"Everything seems boring, I did not learn anything\" is wrongly classified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6zc1fFQCQdo"
      },
      "source": [
        "**Question. 2** Do you feel the organization's policies and benefits are employee-friendly?,\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXw_Zo24hyg8",
        "outputId": "c41b936c-f12a-458d-82ce-9f980e1d161e"
      },
      "source": [
        "sentences = [\"DoÂ youÂ feelÂ theÂ organization'sÂ policiesÂ andÂ benefitsÂ areÂ employee-friendly?\",\n",
        "            \"I feel the policy of the company is quite good, brings good conditions for employees!\",\n",
        "            \"The company does not have a policy to support employees away from home. Should facilitate working from home or remotely\",\n",
        "            \"Overtime payment is quite low, I'm not satisfied about this\",\n",
        "            \"Hi, how are you\",\n",
        "            \"Just fine, but the company should have more outside activities\",\n",
        "            \"They are so nice to me!\",\n",
        "            \"I have to work early tomorrow\",\n",
        "            \"Everything seems boring, I did not learn anything\",\n",
        "            \"I don't know\",\n",
        "            \"The policies and benefits are good!\"\n",
        "]\n",
        "\n",
        "relevant_sents = []\n",
        "irrelevant_sents = []\n",
        "for i,sent in enumerate(sentences[1:]):\n",
        "  vectorizer.bert([sentences[0],sent])\n",
        "  vectors_bert = vectorizer.vectors\n",
        "  #print('Q:',sentences[0])\n",
        "  print(sentences[i+1])\n",
        "  if  spatial.distance.cosine(vectors_bert[0], vectors_bert[1]) < 0.1:\n",
        "  #  print('Relevant')\n",
        "    relevant_sents.append(sent)\n",
        "  else:\n",
        "    irrelevant_sents.append(sent)\n",
        "  #  print('Irrelevant')\n",
        "  print('Distance score:', spatial.distance.cosine(vectors_bert[0], vectors_bert[1]))# calculate_similarity(cleaned_sentences[0], cleaned_sentences[i+1]))\n",
        "  print('---------------')\n",
        "print('\\nSummary\\n')\n",
        "print('Relevant answers:\\n')\n",
        "for sent in relevant_sents:\n",
        "  print('\\t-',sent)\n",
        "\n",
        "print('\\nIrrelevant answers:\\n')\n",
        "for sent in irrelevant_sents:\n",
        "  print('\\t-',sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I feel the policy of the company is quite good, brings good conditions for employees!\n",
            "Distance score: 0.0843970775604248\n",
            "---------------\n",
            "The company does not have a policy to support employees away from home. Should facilitate working from home or remotely\n",
            "Distance score: 0.09428781270980835\n",
            "---------------\n",
            "Overtime payment is quite low, I'm not satisfied about this\n",
            "Distance score: 0.05280721187591553\n",
            "---------------\n",
            "Hi, how are you\n",
            "Distance score: 0.19934695959091187\n",
            "---------------\n",
            "Just fine, but the company should have more outside activities\n",
            "Distance score: 0.057079195976257324\n",
            "---------------\n",
            "They are so nice to me!\n",
            "Distance score: 0.1057860255241394\n",
            "---------------\n",
            "I have to work early tomorrow\n",
            "Distance score: 0.11201858520507812\n",
            "---------------\n",
            "Everything seems boring, I did not learn anything\n",
            "Distance score: 0.1070060133934021\n",
            "---------------\n",
            "I don't know\n",
            "Distance score: 0.11967694759368896\n",
            "---------------\n",
            "The policies and benefits are good!\n",
            "Distance score: 0.11891794204711914\n",
            "---------------\n",
            "\n",
            "Summary\n",
            "\n",
            "Relevant answers:\n",
            "\n",
            "\t- I feel the policy of the company is quite good, brings good conditions for employees!\n",
            "\t- The company does not have a policy to support employees away from home. Should facilitate working from home or remotely\n",
            "\t- Overtime payment is quite low, I'm not satisfied about this\n",
            "\t- Just fine, but the company should have more outside activities\n",
            "\n",
            "Irrelevant answers:\n",
            "\n",
            "\t- Hi, how are you\n",
            "\t- They are so nice to me!\n",
            "\t- I have to work early tomorrow\n",
            "\t- Everything seems boring, I did not learn anything\n",
            "\t- I don't know\n",
            "\t- The policies and benefits are good!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNrEoVDwdwQ7"
      },
      "source": [
        "> One sentence \"The policies and benefits are good!\" is wrongly classified "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "014l2tq1exrf"
      },
      "source": [
        "## Using pre-trained BERT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RnKLIMwf3sq",
        "outputId": "3f7ae6cc-ae0c-4e17-b081-601499b45c59"
      },
      "source": [
        "pip install -q sentence_transformers "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 5.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 11.3MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "b20464f7ecbf458c87ebf52b6e7e1ed0",
            "df9170d392994aef81a23d5883cfb0fb",
            "3e333ed0ee6144f78b25f132bce02f15",
            "2a2233de95454657af4787bef4e824b9",
            "9ed1535008ec41d689c72e6b623857ad",
            "5e81e2e147ce424fbe20872e392bb752",
            "02e62e0aa2e84d3fbad62d31f793f008",
            "8589d6bc84304d38ae1d2cdf3efc93e7"
          ]
        },
        "id": "9BJsUo-RgAwt",
        "outputId": "6ee25fd1-758a-41b3-a19b-0a69ef68be4b"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('nli-distilroberta-base-v2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b20464f7ecbf458c87ebf52b6e7e1ed0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=305203025.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSLFCgyTzdeG"
      },
      "source": [
        "I use 0.6 as threshold for both questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcP9gifEzYX1"
      },
      "source": [
        "**Question 1.** In the last year, do you feel you have grown in terms of your knowledge and capabilities?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtZfUdc3s0pF",
        "outputId": "add7fa2b-d271-46f7-f0b8-a61b3375da92"
      },
      "source": [
        "sentences = [\n",
        "    \"In the last year, do you feel you have grown in terms of your knowledge and capabilities?\",\n",
        "    \"Yes, I do. I have improved my technical skill.\",\n",
        "    \"I play basketball very well.\",\n",
        "    \"Yes, I do. I have improved my technical skill as well as my ability of working in a team\",\n",
        "    \"I learned a lot in my school, I worked very hard\",\n",
        "    \"You are so bad.\",\n",
        "    \"I almost learned nothing in the last year, the job is unsuitable with my career path\",\n",
        "    \"I have learned new techniques and improved my communication skill\",\n",
        "    \"Everything seems boring, I did not learn anything\",\n",
        "]\n",
        "\n",
        "sentence_embeddings = model.encode(sentences)\n",
        "relevant_sents = []\n",
        "irrelevant_sents = []\n",
        "for i,sent in enumerate(sentences[1:]):\n",
        "  #print('Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities?')\n",
        "  print(sentences[i+1])\n",
        "  if  spatial.distance.cosine(sentence_embeddings[0], sentence_embeddings[i+1]) < 0.6:\n",
        "   # print('Relevant')\n",
        "    relevant_sents.append(sent)\n",
        "  else:\n",
        "   # print('Irrelevant')\n",
        "    irrelevant_sents.append(sent)\n",
        "  print('Distance score:', spatial.distance.cosine(sentence_embeddings[0], sentence_embeddings[i+1]))# calculate_similarity(cleaned_sentences[0], cleaned_sentences[i+1]))\n",
        "  print('---------------')\n",
        "\n",
        "print('\\nSummary\\n')\n",
        "print('Relevant answers:\\n')\n",
        "for sent in relevant_sents:\n",
        "  print('\\t-',sent)\n",
        "\n",
        "print('\\nIrrelevant answers:\\n')\n",
        "for sent in irrelevant_sents:\n",
        "  print('\\t-',sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yes, I do. I have improved my technical skill.\n",
            "Distance score: 0.5134833753108978\n",
            "---------------\n",
            "I play basketball very well.\n",
            "Distance score: 0.8135423809289932\n",
            "---------------\n",
            "Yes, I do. I have improved my technical skill as well as my ability of working in a team\n",
            "Distance score: 0.5630861520767212\n",
            "---------------\n",
            "I learned a lot in my school, I worked very hard\n",
            "Distance score: 0.670462429523468\n",
            "---------------\n",
            "You are so bad.\n",
            "Distance score: 0.8805501386523247\n",
            "---------------\n",
            "I almost learned nothing in the last year, the job is unsuitable with my career path\n",
            "Distance score: 0.7736584097146988\n",
            "---------------\n",
            "I have learned new techniques and improved my communication skill\n",
            "Distance score: 0.5645861327648163\n",
            "---------------\n",
            "Everything seems boring, I did not learn anything\n",
            "Distance score: 1.0033836120273918\n",
            "---------------\n",
            "\n",
            "Summary\n",
            "\n",
            "Relevant answers:\n",
            "\n",
            "\t- Yes, I do. I have improved my technical skill.\n",
            "\t- Yes, I do. I have improved my technical skill as well as my ability of working in a team\n",
            "\t- I have learned new techniques and improved my communication skill\n",
            "\n",
            "Irrelevant answers:\n",
            "\n",
            "\t- I play basketball very well.\n",
            "\t- I learned a lot in my school, I worked very hard\n",
            "\t- You are so bad.\n",
            "\t- I almost learned nothing in the last year, the job is unsuitable with my career path\n",
            "\t- Everything seems boring, I did not learn anything\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QNefIfEtetg"
      },
      "source": [
        "> Two sentences: \"I almost learned nothing in the last year, the job is unsuitable with my career path\" and \"Everything seems boring, I did not learn anything\" are wrongly classified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9T9BtlUpqJ3"
      },
      "source": [
        "**Question 2.**DoÂ youÂ feelÂ theÂ organization'sÂ policiesÂ andÂ benefitsÂ areÂ employee-friendly?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98swv02cgR6P",
        "outputId": "04ea2c51-4f03-44b5-bac7-0bac0f987c6e"
      },
      "source": [
        "sentences = [\n",
        "   \"DoÂ youÂ feelÂ theÂ organization'sÂ policiesÂ andÂ benefitsÂ areÂ employee-friendly?\",\n",
        "    \"IÂ feelÂ theÂ policyÂ ofÂ companyÂ isÂ quietÂ good,Â bringsÂ goodÂ conditionsÂ forÂ employees!\",\n",
        "    \"TheÂ companyÂ doesÂ notÂ haveÂ aÂ policyÂ toÂ supportÂ employeesÂ awayÂ fromÂ home.Â ShouldÂ facilitateÂ workingÂ fromÂ homeÂ orÂ remotely\",\n",
        "    \"OvertimeÂ paymentÂ isÂ quiteÂ low,Â I'mÂ notÂ satisfiedÂ aboutÂ this\",\n",
        "    \"Hi,Â howÂ areÂ you\",\n",
        "    \"JustÂ fine,Â butÂ theÂ companyÂ shouldÂ haveÂ moreÂ outsideÂ activities\",\n",
        "    \"TheyÂ areÂ soÂ niceÂ toÂ me!\",\n",
        "    \"IÂ haveÂ toÂ workÂ earlyÂ tomorrow\",\n",
        "    \"EverythingÂ seemsÂ boring,Â IÂ didÂ notÂ learnÂ anything\",\n",
        "    \"IÂ don'tÂ know\",\n",
        "    \"TheÂ policiesÂ andÂ benefitsÂ areÂ good!\"\n",
        "]\n",
        "\n",
        "sentence_embeddings = model.encode(sentences)\n",
        "relevant_sents = []\n",
        "irrelevant_sents = []\n",
        "for i,sent in enumerate(sentences[1:]):\n",
        " # print('Q: In the last year, do you feel you have grown in terms of your knowledge and capabilities?')\n",
        "  print(sentences[i+1])\n",
        "  if  spatial.distance.cosine(sentence_embeddings[0], sentence_embeddings[i+1]) < 0.6:\n",
        "  #  print('Relevant')\n",
        "    relevant_sents.append(sent)\n",
        "  else:\n",
        "  #  print('Irrelevant')\n",
        "    irrelevant_sents.append(sent)\n",
        "  print('Distance score:', spatial.distance.cosine(sentence_embeddings[0], sentence_embeddings[i+1]))# calculate_similarity(cleaned_sentences[0], cleaned_sentences[i+1]))\n",
        "  print('---------------')\n",
        "\n",
        "print('\\nSummary\\n')\n",
        "print('Relevant answers:\\n')\n",
        "for sent in relevant_sents:\n",
        "  print('\\t-',sent)\n",
        "\n",
        "print('\\nIrrelevant answers:\\n')\n",
        "for sent in irrelevant_sents:\n",
        "  print('\\t-',sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IÂ feelÂ theÂ policyÂ ofÂ companyÂ isÂ quietÂ good,Â bringsÂ goodÂ conditionsÂ forÂ employees!\n",
            "Distance score: 0.34289824962615967\n",
            "---------------\n",
            "TheÂ companyÂ doesÂ notÂ haveÂ aÂ policyÂ toÂ supportÂ employeesÂ awayÂ fromÂ home.Â ShouldÂ facilitateÂ workingÂ fromÂ homeÂ orÂ remotely\n",
            "Distance score: 0.4734971523284912\n",
            "---------------\n",
            "OvertimeÂ paymentÂ isÂ quiteÂ low,Â I'mÂ notÂ satisfiedÂ aboutÂ this\n",
            "Distance score: 0.7398489415645599\n",
            "---------------\n",
            "Hi,Â howÂ areÂ you\n",
            "Distance score: 0.6443432569503784\n",
            "---------------\n",
            "JustÂ fine,Â butÂ theÂ companyÂ shouldÂ haveÂ moreÂ outsideÂ activities\n",
            "Distance score: 0.45370060205459595\n",
            "---------------\n",
            "TheyÂ areÂ soÂ niceÂ toÂ me!\n",
            "Distance score: 0.7259829044342041\n",
            "---------------\n",
            "IÂ haveÂ toÂ workÂ earlyÂ tomorrow\n",
            "Distance score: 0.8282761871814728\n",
            "---------------\n",
            "EverythingÂ seemsÂ boring,Â IÂ didÂ notÂ learnÂ anything\n",
            "Distance score: 0.9315886124968529\n",
            "---------------\n",
            "IÂ don'tÂ know\n",
            "Distance score: 0.9296606630086899\n",
            "---------------\n",
            "TheÂ policiesÂ andÂ benefitsÂ areÂ good!\n",
            "Distance score: 0.45825880765914917\n",
            "---------------\n",
            "\n",
            "Summary\n",
            "\n",
            "Relevant answers:\n",
            "\n",
            "\t- IÂ feelÂ theÂ policyÂ ofÂ companyÂ isÂ quietÂ good,Â bringsÂ goodÂ conditionsÂ forÂ employees!\n",
            "\t- TheÂ companyÂ doesÂ notÂ haveÂ aÂ policyÂ toÂ supportÂ employeesÂ awayÂ fromÂ home.Â ShouldÂ facilitateÂ workingÂ fromÂ homeÂ orÂ remotely\n",
            "\t- JustÂ fine,Â butÂ theÂ companyÂ shouldÂ haveÂ moreÂ outsideÂ activities\n",
            "\t- TheÂ policiesÂ andÂ benefitsÂ areÂ good!\n",
            "\n",
            "Irrelevant answers:\n",
            "\n",
            "\t- OvertimeÂ paymentÂ isÂ quiteÂ low,Â I'mÂ notÂ satisfiedÂ aboutÂ this\n",
            "\t- Hi,Â howÂ areÂ you\n",
            "\t- TheyÂ areÂ soÂ niceÂ toÂ me!\n",
            "\t- IÂ haveÂ toÂ workÂ earlyÂ tomorrow\n",
            "\t- EverythingÂ seemsÂ boring,Â IÂ didÂ notÂ learnÂ anything\n",
            "\t- IÂ don'tÂ know\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GBwbSp0hh7d"
      },
      "source": [
        "> One sentence: \"Overtime payment is quite low, I'm not satisfied about this\" is wrongly classified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRTCkyRKlDzs"
      },
      "source": [
        "# Part II Sentiment analysis\n",
        "\n",
        "> After having the answers, we classify the answers into three groups: `positive`, `negative` or `neutral` \n",
        "\n",
        "> The problem can be solved easily when we have dataset. But in the case we don't have any. I propose a statistic method:\n",
        "\n",
        ">> I use two dictionaries (LoughranMcDonald and Twitter) including: positive and negative words. Then I count the number of negative and positive words in the answer to calculate polarity score\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mKk9mRElPPj",
        "outputId": "9834a786-b8e5-4e9f-b4ab-486650e4ae5a"
      },
      "source": [
        "LoughranMcDonald_negative = pd.read_excel('/content/drive/MyDrive/LoughranMcDonald_SentimentWordLists_2018.xlsx', sheet_name=1, header=None)\n",
        "LoughranMcDonald_negative = LoughranMcDonald_negative.values.flatten()\n",
        "\n",
        "LoughranMcDonald_positive = pd.read_excel('/content/drive/MyDrive/LoughranMcDonald_SentimentWordLists_2018.xlsx', sheet_name=2, header=None)\n",
        "LoughranMcDonald_positive = LoughranMcDonald_positive.values.flatten()\n",
        "\n",
        "f = open('/content/drive/MyDrive/twitter-negative-words.txt',encoding=\"ISO-8859-1\")\n",
        "twitter_negative = f.read()\n",
        "twitter_negative = twitter_negative.split('\\n')\n",
        "\n",
        "f = open('/content/drive/MyDrive/twitter-positive-words.txt',encoding=\"ISO-8859-1\")\n",
        "twitter_positive = f.read()\n",
        "twitter_positive = twitter_positive.split('\\n')\n",
        "\n",
        "positive_words = [item.lower() for item in LoughranMcDonald_positive]\n",
        "negative_words = [item.lower() for item in LoughranMcDonald_negative]\n",
        "\n",
        "for item in twitter_positive:\n",
        "  if item not in positive_words:\n",
        "    positive_words.append(item)\n",
        "\n",
        "for item in twitter_negative:\n",
        "  if item not in negative_words:\n",
        "    negative_words.append(item)\n",
        "\n",
        "print('Number of Negative words:', len(negative_words))\n",
        "print('Number of Positive words:', len(positive_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative words: 6298\n",
            "Number of Positive words: 2169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NfZc86xtSK9"
      },
      "source": [
        "def calculate_polarity(doc):\n",
        "  neg_score = 0\n",
        "  pos_score = 0\n",
        "\n",
        "  for token in doc:\n",
        "    if token.text.lower() in negative_words:\n",
        "      neg_score += 1\n",
        "    if token.text.lower() in positive_words:\n",
        "      pos_score += 1\n",
        "  polarity_score = (pos_score-neg_score)/((pos_score+neg_score)+0.0000001)\n",
        "\n",
        "  return polarity_score\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-UvM-1S_l7B",
        "outputId": "d94f9052-808f-486c-c6a4-536b40461322"
      },
      "source": [
        "A1= [\n",
        "    \"Yes, I do. I have improved my technical skill.\",\n",
        "    \"I play basketball very well.\",\n",
        "    \"Yes, I do. I have improved my technical skill as well as my ability of working in a team\",\n",
        "    \"I learned a lot in my school, I worked very hard\",\n",
        "    \"You are so bad.\",\n",
        "    \"I almost learned nothing in the last year, the job is unsuitable with my career path\",\n",
        "    \"I have learned new techniques and improved my communication skill\",\n",
        "    \"Everything seems boring, I did not learn anything\",\n",
        "    \"Have improved more than before, being exposed to many practical jobs, applying learned knowledge into practice, solving many problems at work\",\n",
        "    \"It's quite regretful and time-consuming because I did not work according to my passion, so I could not consolidate any more knowledge\",\n",
        "    \"IÂ feelÂ theÂ policyÂ ofÂ companyÂ isÂ quiteÂ good,Â bringsÂ goodÂ conditionsÂ forÂ employees!\",\n",
        "    \"TheÂ companyÂ doesÂ notÂ haveÂ aÂ policyÂ toÂ supportÂ employeesÂ awayÂ fromÂ home.Â ShouldÂ facilitateÂ workingÂ fromÂ homeÂ orÂ remotely\",\n",
        "    \"OvertimeÂ paymentÂ isÂ quiteÂ low,Â I'mÂ notÂ satisfiedÂ aboutÂ this\",\n",
        "    \"Hi,Â howÂ areÂ you\",\n",
        "    \"JustÂ fine,Â butÂ theÂ companyÂ shouldÂ haveÂ moreÂ outsideÂ activities\",\n",
        "    \"TheyÂ areÂ soÂ niceÂ toÂ me!\",\n",
        "    \"IÂ haveÂ toÂ workÂ earlyÂ tomorrow\",\n",
        "    \"IÂ don'tÂ know\",\n",
        "    \"TheÂ policiesÂ andÂ benefitsÂ areÂ good!\"\n",
        "]\n",
        "\n",
        "positive_sents = []\n",
        "negative_sents = []\n",
        "neutral_sents = []\n",
        "for sent in A1:\n",
        "  doc = nlp(sent)\n",
        "  polarity_score = calculate_polarity(doc)\n",
        "  if polarity_score < 0: \n",
        "    negative_sents.append(sent)\n",
        "  elif polarity_score > 0:\n",
        "    positive_sents.append(sent)\n",
        "  else:\n",
        "    neutral_sents.append(sent)\n",
        "\n",
        "print('\\nSummary\\n')\n",
        "print('Positive:\\n')\n",
        "\n",
        "for sent in positive_sents:\n",
        "  print('\\t-',sent)\n",
        "\n",
        "print('\\nNegative:\\n')\n",
        "for sent in negative_sents:\n",
        "  print('\\t-',sent)\n",
        "\n",
        "print('\\nNeutral:\\n')\n",
        "for sent in neutral_sents:\n",
        "  print('\\t-',sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Summary\n",
            "\n",
            "Positive:\n",
            "\n",
            "\t- Yes, I do. I have improved my technical skill.\n",
            "\t- I play basketball very well.\n",
            "\t- Yes, I do. I have improved my technical skill as well as my ability of working in a team\n",
            "\t- I have learned new techniques and improved my communication skill\n",
            "\t- Have improved more than before, being exposed to many practical jobs, applying learned knowledge into practice, solving many problems at work\n",
            "\t- It's quite regretful and time-consuming because I did not work according to my passion, so I could not consolidate any more knowledge\n",
            "\t- IÂ feelÂ theÂ policyÂ ofÂ companyÂ isÂ quiteÂ good,Â bringsÂ goodÂ conditionsÂ forÂ employees!\n",
            "\t- TheÂ companyÂ doesÂ notÂ haveÂ aÂ policyÂ toÂ supportÂ employeesÂ awayÂ fromÂ home.Â ShouldÂ facilitateÂ workingÂ fromÂ homeÂ orÂ remotely\n",
            "\t- OvertimeÂ paymentÂ isÂ quiteÂ low,Â I'mÂ notÂ satisfiedÂ aboutÂ this\n",
            "\t- JustÂ fine,Â butÂ theÂ companyÂ shouldÂ haveÂ moreÂ outsideÂ activities\n",
            "\t- TheyÂ areÂ soÂ niceÂ toÂ me!\n",
            "\t- IÂ haveÂ toÂ workÂ earlyÂ tomorrow\n",
            "\t- TheÂ policiesÂ andÂ benefitsÂ areÂ good!\n",
            "\n",
            "Negative:\n",
            "\n",
            "\t- You are so bad.\n",
            "\t- I almost learned nothing in the last year, the job is unsuitable with my career path\n",
            "\t- Everything seems boring, I did not learn anything\n",
            "\n",
            "Neutral:\n",
            "\n",
            "\t- I learned a lot in my school, I worked very hard\n",
            "\t- Hi,Â howÂ areÂ you\n",
            "\t- IÂ don'tÂ know\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jQfk8G3A01p"
      },
      "source": [
        "> Not bad result!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLf8iGbMHyf1"
      },
      "source": [
        "**Create user interaction (for later)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47BwJB98Lash"
      },
      "source": [
        "exit_list = ['exit', 'see you later', 'bye', 'quit', 'break']\n",
        "print('Bot: Hi, I have some questions for you!',)\n",
        "print(\"In the last year, do you feel you have grown in terms of your knowledge and capabilities?\",)\n",
        "while(True):\n",
        "  user_input = input()\n",
        "  if user_input.lower() in exit_list:\n",
        "    print('Bot: Chat with you later!')\n",
        "    break\n",
        "  else:\n",
        "    sentences = [\n",
        "     \"In the last year, do you feel you have grown in terms of your knowledge and capabilities?\",\n",
        "     user_input\n",
        "    ]\n",
        "    vectorizer.bert(sentences)\n",
        "    vectors_bert = vectorizer.vectors\n",
        "    print('Distance score:', spatial.distance.cosine(vectors_bert[0], vectors_bert[1]))# calculate_similarity(cleaned_sentences[0], cleaned_sentences[i+1]))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh3AaHn7DJJ6"
      },
      "source": [
        "# Conclusion and Further work\n",
        "\n",
        "> **sent2vec based on pretrained BERT and Word2Vec** give best results. We can use this method to label data <br>\n",
        "> **sentiment analysis based on statistic** give a baseline, because it count on word-base, i.e: it can't distinguish between `not sastified` and `sastified` \n",
        "\n",
        "> **Furthur work**: We can implements the approaches which I have mentioned on each part when we collect and label data manually.  "
      ]
    }
  ]
}